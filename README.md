# ğŸ“ Vidya AI - Educational Content Generator

An AI-powered educational platform that generates engaging videos with voice narration, animated visuals, and structured learning content.

## âœ¨ Features

- ğŸ¤– **AI-Powered Content Generation**: Uses Groq AI and OpenAI to create educational content
- ğŸ¬ **Video Generation**: Creates educational videos with clean white theme
- ğŸµ **Voice Narration**: Text-to-speech with multiple fallback options
- ğŸ“± **Mobile Responsive**: Fully optimized for mobile devices
- ğŸ¨ **Professional Design**: Clean, modern UI inspired by Coursera/Khan Academy
- âš¡ **Fast Performance**: Optimized for speed and mobile networks

## ğŸš€ Live Demo

- **Frontend**: [Deployed on Netlify](https://your-app-name.netlify.app)
- **Backend**: [Deployed on Heroku/Railway](https://your-backend-url.herokuapp.com)

## ğŸ› ï¸ Tech Stack

### Frontend
- **Next.js 14** - React framework with App Router
- **Tailwind CSS** - Utility-first CSS framework
- **TypeScript** - Type-safe JavaScript
- **Lucide React** - Beautiful icons

### Backend
- **FastAPI** - Modern Python web framework
- **Groq AI** - Fast AI inference
- **Azure Speech Services** - Text-to-speech
- **MoviePy** - Video processing
- **PIL/Pillow** - Image generation

## ğŸ“± Mobile Responsive Features

- âœ… Responsive breakpoints (xs, sm, md, lg, xl)
- âœ… Touch-friendly interface (44px minimum touch targets)
- âœ… Mobile-optimized typography
- âœ… Adaptive video player
- âœ… Fast loading on mobile networks
- âœ… Battery-efficient design

## ğŸ¯ Content Format

Each educational video follows a structured format:

1. **Title Section**: Big title with emoji and centered text
2. **Subtitle/Question**: Bold italic question format
3. **Main Explanation**: 3-5 short sentences in a clean box
4. **Key Points**: 3-4 bullet points (max 10 words each)
5. **Visual Instruction**: Simple animation/graphic suggestion

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.12+
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/helloraviai-ctrl/vidyaaitest.git
   cd vidyaaitest
   ```

2. **Install frontend dependencies**
   ```bash
   npm install
   ```

3. **Set up backend**
   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

4. **Environment variables**
   ```bash
   # Copy and configure environment variables
   cp backend/env.example backend/.env
   # Edit backend/.env with your API keys
   ```

5. **Run the application**
   ```bash
   # Terminal 1: Start backend
   cd backend
   source venv/bin/activate
   python main.py

   # Terminal 2: Start frontend
   npm run dev
   ```

6. **Open your browser**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000

## ğŸŒ Deployment

### Netlify (Frontend)

1. **Connect to GitHub**
   - Go to [Netlify](https://netlify.com)
   - Connect your GitHub repository
   - Select `helloraviai-ctrl/vidyaaitest`

2. **Build Settings**
   - Build command: `npm run build`
   - Publish directory: `out`
   - Node version: `18`

3. **Environment Variables**
   - Add any required environment variables in Netlify dashboard

### Backend Deployment

Deploy the backend to your preferred platform:

- **Heroku**: Use the included `Procfile`
- **Railway**: Connect GitHub repository
- **Render**: Use the build configuration
- **DigitalOcean**: Use App Platform

## ğŸ“ Project Structure

```
vidyaaitest/
â”œâ”€â”€ app/                    # Next.js app directory
â”‚   â”œâ”€â”€ globals.css        # Global styles
â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â””â”€â”€ page.tsx           # Main page
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # Main application
â”‚   â”œâ”€â”€ services/         # AI and video services
â”‚   â”œâ”€â”€ models/           # Data models
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ public/               # Static assets
â”œâ”€â”€ netlify.toml         # Netlify configuration
â”œâ”€â”€ next.config.js       # Next.js configuration
â”œâ”€â”€ tailwind.config.js   # Tailwind configuration
â””â”€â”€ package.json         # Node.js dependencies
```

## ğŸ”§ Configuration

### Environment Variables

Create `backend/.env` with:

```env
# AI Services
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=your_openai_api_key

# Azure Speech (optional)
AZURE_SPEECH_KEY=your_azure_speech_key
AZURE_SPEECH_REGION=your_azure_region

# Other settings
DEBUG=True
```

### Customization

- **Colors**: Edit `tailwind.config.js` for theme colors
- **Content Format**: Modify `services/ai_service_manager.py`
- **Video Theme**: Update `services/animation_service.py`
- **Mobile Breakpoints**: Adjust in `app/page.tsx`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Groq AI](https://groq.com) for fast AI inference
- [Azure Speech Services](https://azure.microsoft.com/en-us/services/cognitive-services/speech-services/) for TTS
- [Next.js](https://nextjs.org) for the amazing React framework
- [Tailwind CSS](https://tailwindcss.com) for utility-first styling

## ğŸ“ Support

If you have any questions or need help:

- ğŸ“§ Email: your-email@example.com
- ğŸ› Issues: [GitHub Issues](https://github.com/helloraviai-ctrl/vidyaaitest/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/helloraviai-ctrl/vidyaaitest/discussions)

---

**Made with â¤ï¸ for education and learning**